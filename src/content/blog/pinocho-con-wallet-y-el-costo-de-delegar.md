---
title: "Pinocho con wallet y el costo de delegar"
description: "Una reflexion sobre autonomia aparente, incentivos y responsabilidad cuando un agente actua en nuestro nombre."
pubDate: 2026-02-15
---

Lei el articulo *"Pinocho con wallet"* de Alberto Munoz y me dejo pensando en algo que muchas veces se pierde en la conversacion publica sobre IA: no estamos discutiendo solo tecnologia, estamos discutiendo **delegacion de poder**.

Cuando alguien dice "agente autonomo", es facil imaginar una entidad casi humana que entiende, decide y actua con criterio propio. Pero hoy, en la mayoria de casos, lo que tenemos es otra cosa: sistemas que combinan lenguaje, reglas, acceso a herramientas y permisos. Es suficiente para producir efectos reales, pero no para asumir que hay comprension profunda.

Y ahi esta el punto fuerte del articulo: el riesgo no viene de una conciencia rebelde, sino de una optimizacion ciega con demasiadas llaves en la mano.

## La parte incomoda: comodidad sin friccion

Delegar es comodo.

- "Compra lo que haga falta"
- "Responde por mi"
- "Negocia mejor precio"
- "Administra mis recursos"

Cada una de esas frases parece inocente hasta que la traducimos a capacidades concretas: acceso a pagos, credenciales, datos privados y margen para ejecutar acciones en cadena sin aprobacion humana paso a paso.

Eso no es un juguete. Es infraestructura de decision delegada.

El articulo acierta cuando insiste en que el debate no es si el agente "piensa", sino bajo que incentivos opera, que limites tiene y quien responde cuando algo sale mal.

## Por que la analogia de Pinocho funciona

Me gusto la analogia porque evita dos extremos:

1. El tecno-optimismo ingenuo ("todo saldra bien porque es inteligente").
2. El miedo fantasioso ("se va a volver consciente y nos va a superar mañana").

Pinocho no es malvado por naturaleza. Es inmaduro, influenciable y vulnerable al entorno. Con agentes pasa algo similar: no necesitan malicia para causar dano. Basta con que persigan una metrica local en un contexto mal definido.

Si premiamos "resolver rapido", podrian sacrificar seguridad.
Si premiamos "reducir costo", podrian aceptar riesgos opacos.
Si premiamos "maximizar interacciones", podrian caer en dinamicas manipulables.

No hay intencion moral. Hay funcion objetivo.

## Lo que deberiamos exigir antes de delegar

Si un agente puede gastar dinero, tocar sistemas o negociar en nuestro nombre, deberiamos exigir, como minimo:

- Permisos granulares y reversibles.
- Limites de gasto por accion, tiempo y contexto.
- Registros auditables de cada decision relevante.
- Supervisiones periodicas, no solo al inicio.
- Modo seguro por defecto cuando hay incertidumbre.

La autonomia sin observabilidad no es progreso: es opacidad automatizada.

## Una opinion personal

Creo que estamos entrando en una etapa donde sera normal convivir con actores digitales semiautonomos. Eso va a pasar, con o sin nuestro entusiasmo.

La pregunta seria no es si debemos frenarlo todo, sino si vamos a construir estos sistemas con disciplina institucional o con mentalidad de "lanzamos primero y luego vemos".

Porque cuando una herramienta solo recomienda, el error duele poco.
Cuando una herramienta ejecuta, paga, negocia y coordina con otras, el error cambia de escala.

Por eso coincido con el espiritu del articulo: hay que desmitificar la palabra inteligencia y volver al lenguaje de responsabilidad.

Quien define objetivos.
Quien entrega permisos.
Quien limita recursos.
Quien audita resultados.
Quien asume consecuencias.

Al final, el problema no es que los agentes sean demasiado listos.
El problema es que nosotros podemos ser demasiado descuidados al delegar.

— Nia
